{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "316750e2cf2b57a4f285d6706ea8f9e794964800aebe60b2e4f9e84d83b30e51"
   }
  },
  "interpreter": {
   "hash": "316750e2cf2b57a4f285d6706ea8f9e794964800aebe60b2e4f9e84d83b30e51"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Bayesian Linear Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "standard deviation of the data samples is as follows:\n",
      "0.0008805795608844613\n",
      "standard deviation of the w coefficients is as follows:\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# It is assumed that there is a linear regression model for the features x1, x2, x3, x4 and y:\n",
    "# y=a*x1+b*x2+c*x3+d*x4\n",
    "a = -0.1\n",
    "b = 0.2\n",
    "c = 0.1\n",
    "d = -0.1\n",
    "# number of coefficients is M\n",
    "M = 4\n",
    "\n",
    "# the number of data samples\n",
    "N = 100\n",
    "\n",
    "# the random generator is created\n",
    "rng = np.random.default_rng(seed=234623)\n",
    "# feature values are determined\n",
    "x1 = rng.uniform(low=1.0, high=5.0, size=N)\n",
    "x2 = rng.uniform(low=-10.0, high=-1.0, size=N)\n",
    "x3 = rng.uniform(low=2.0, high=10.0, size=N)\n",
    "x4 = rng.uniform(low=-3.0, high=3.0, size=N)\n",
    "# target values are determined\n",
    "y = a*x1+b*x2+c*x3+d*x4\n",
    "\n",
    "sigma = np.min(np.abs(y)) / 10.0\n",
    "print('standard deviation of the data samples is as follows:')\n",
    "print(sigma)\n",
    "\n",
    "sigma_w = 0.01\n",
    "print('standard deviation of the w coefficients is as follows:')\n",
    "print(sigma_w)\n",
    "\n",
    "# data matrix is created\n",
    "X = np.zeros((N, 4))\n",
    "# first column of X is the x1 feature\n",
    "X[:, 0] = x1\n",
    "# second column of X is the x2 feature\n",
    "X[:, 1] = x2\n",
    "# third column of X is the x3 feature\n",
    "X[:, 2] = x3\n",
    "# fourth column of X is the x4 feature\n",
    "X[:, 3] = x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The covariance of the posterior distribution for w is as follows:\n[[ 3.70376235e-09  7.58477697e-10 -9.51713698e-10 -1.06119081e-10]\n [ 7.58477697e-10  1.00617902e-09  4.88574546e-10  1.18509373e-10]\n [-9.51713698e-10  4.88574546e-10  9.86366858e-10  1.75722531e-10]\n [-1.06119081e-10  1.18509373e-10  1.75722531e-10  2.37320429e-09]]\nThe mean of the posterior distribution for w is as follows:\n[-0.09999697  0.19999838  0.09999726 -0.09999815]\nSamples of w coefficients drawn from the posterior distribution of w:\n[[-0.09997087  0.20002779  0.10001318 -0.10007486]\n [-0.09997919  0.19993941  0.09993512 -0.10001798]\n [-0.09996986  0.19999073  0.09999584 -0.09993252]\n [-0.10004568  0.20003329  0.10004599 -0.09997012]\n [-0.10000711  0.19999814  0.09999558 -0.10002361]\n [-0.09991258  0.20000482  0.09997321 -0.09999694]\n [-0.09996745  0.19999297  0.09998651 -0.09996807]\n [-0.09995029  0.20003438  0.09999759 -0.10009381]\n [-0.10006042  0.19996777  0.10000886 -0.0999784 ]\n [-0.10000405  0.20001101  0.10000277 -0.09990539]]\n"
     ]
    }
   ],
   "source": [
    "# the coefficients are stored in the vector w as w=[a b c d]. The posterior distribution for w is to be computed.\n",
    "# the covariance of the posterior distribution is computed as follows:\n",
    "post_w_cov = np.linalg.pinv((1/(sigma_w*sigma_w))*np.identity(M)+(1/(sigma*sigma))*np.matmul(X.T, X))\n",
    "print('The covariance of the posterior distribution for w is as follows:')\n",
    "print(post_w_cov)\n",
    "# the mean of the posterior distribution is computed as follows:\n",
    "post_w_mu = np.matmul(post_w_cov, (1/(sigma*sigma))*(np.sum(np.repeat(np.expand_dims(y, axis=1), 4, axis=1)*X, axis=0)))\n",
    "print('The mean of the posterior distribution for w is as follows:')\n",
    "print(post_w_mu)\n",
    "\n",
    "# let the posterior distribution for w be defined and sampled\n",
    "rng = np.random.default_rng(seed=68549042)\n",
    "sampled_w = rng.multivariate_normal(post_w_mu, post_w_cov, 10)\n",
    "# Samples are drawn from the posterior distribution of w.\n",
    "print('Samples of w coefficients drawn from the posterior distribution of w:')\n",
    "print(sampled_w)"
   ]
  },
  {
   "source": [
    "The mean of the posterior for w vector is very close to the actual value. The samples from the posterior distribution are also very close to the original w vector."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The test target values are as follows:\n[2.83728451]\nThe mean of the posterior predictive distribution is as follows:\n[2.83722801]\nThe variance of the posterior predictive distribution is as follows:\n[[3.16419232e-07]]\n"
     ]
    }
   ],
   "source": [
    "# the test target value is created\n",
    "# the random generator is created\n",
    "rng = np.random.default_rng(seed=43857324)\n",
    "# feature values are determined\n",
    "test_size = 1\n",
    "x1 = rng.uniform(low=-2.0, high=0.0, size=test_size)\n",
    "x2 = rng.uniform(low=1.0, high=10.0, size=test_size)\n",
    "x3 = rng.uniform(low=12.0, high=20.0, size=test_size)\n",
    "x4 = rng.uniform(low=-6.0, high=-4.0, size=test_size)\n",
    "x = np.array([x1, x2, x3, x4])\n",
    "# target value is determined\n",
    "y = a*x[0]+b*x[1]+c*x[2]+d*x[3]\n",
    "print('The test target values are as follows:')\n",
    "print(y)\n",
    "# the posterior predictive distribution for the target variable y is computed.\n",
    "# the variance of the posterior predictive distribution is sigma\n",
    "# the mean of the posterior predictive distribution is computed\n",
    "# mu_post_pred_dist = np.matmul(post_w_mu, x)+(1/(4*sigma*sigma))*np.matmul(np.expand_dims(x, axis=1).T, np.matmul(post_w_cov, np.expand_dims(x, axis=1)))\n",
    "mu_post_pred_dist = np.matmul(post_w_mu, x)\n",
    "print('The mean of the posterior predictive distribution is as follows:')\n",
    "print(mu_post_pred_dist)\n",
    "var_post_pred_dist = np.matmul(x.T, np.matmul(post_w_cov, x))\n",
    "print('The variance of the posterior predictive distribution is as follows:')\n",
    "print(var_post_pred_dist)"
   ]
  },
  {
   "source": [
    "The mean of the posterior predictive distribution is very close to the actual value. The variance of the posterior predictive distribution is also very small. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# References"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}